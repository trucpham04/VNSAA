import streamlit as st
from underthesea import word_tokenize
from transformers import pipeline
import time
from database import delete_all_records, initialize_database, save_to_sqlite, load_data_from_sqlite
from constant import CORRECTION_DICT
from utils import show_pipeline_steps, show_sentiment_result

# =========================== Model Loading ===========================
@st.cache_resource
def load_model_pipeline():
    print("Loading model pipeline...")
    start_time = time.time()

    sentiment_pipeline = pipeline(
        task="sentiment-analysis",
        model="wonrax/phobert-base-vietnamese-sentiment"
    )

    end_time = time.time()
    print(f"Model has been loaded! (Took {end_time - start_time:.2f} seconds)")
    return sentiment_pipeline

# =========================== Preprocessing ===========================
def normalize_text(text: str) -> str:
    normalized_sentence = text.strip().lower()
    return normalized_sentence

def correct_slang_words(text: str) -> str:
    words = text.split()
    corrected_words = [CORRECTION_DICT.get(w, w) for w in words]
    corrected_sentence = " ".join(corrected_words)
    return corrected_sentence

def tokenize_text(text: str) -> str:
    tokenized_list = word_tokenize(text)
    processed_tokens = []
    for token in tokenized_list:
        processed_tokens.append(token.replace(" ", "_"))
    final_text = " ".join(processed_tokens)
    return final_text

# =========================== Sentiment Classification ===========================
def classify_sentiment(text: str, sentiment_pipeline):
    if sentiment_pipeline is None:
        raise Exception("Pipeline has not been initialized.")
    
    raw_result = sentiment_pipeline(text)

    sentiment = max(raw_result, key=lambda x: x['score'])

    if sentiment['score'] < 0.5:
        sentiment['label'] = "NEU"

    def get_sentiment_label(label: str) -> str:
        match label:
            case "POS":
                return "POSITIVE"
            case "NEG":
                return "NEGATIVE"
            case "NEU":
                return "NEUTRAL"

    sentiment['label'] = get_sentiment_label(sentiment['label'])

    return sentiment

# =========================== Full Pipeline ===========================
def full_pipeline(text: str, sentiment_pipeline):
    try:
        # === B∆∞·ªõc 1: Ti·ªÅn x·ª≠ l√Ω

        # Chu·∫©n h√≥a c√¢u
        normalized_sentence = normalize_text(text)

        # S·ª≠a nh·ªØng t·ª´ kh√¥ng d·∫•u, vi·∫øt t·∫Øt, t·ª´ l√≥ng
        corrected_text = correct_slang_words(normalized_sentence)

        # Ph√¢n ƒëo·∫°n t·ª´
        tokenized_text = tokenize_text(corrected_text)

        # === B∆∞·ªõc 2: Ph√¢n lo·∫°i c·∫£m x√∫c
        sentiment = classify_sentiment(tokenized_text, sentiment_pipeline)

        # === B∆∞·ªõc 3: H·ª£p nh·∫•t v√† x·ª≠ l√Ω l·ªói
        result = {
            "text": tokenized_text,
            "sentiment": sentiment['label'],
        }

        # L∆∞u k·∫øt qu·∫£ v√†o database
        save_to_sqlite(result)

        # Ki·ªÉm tra h·ª£p l·ªá
        if len(result["text"]) < 5:
            return None, "C√¢u kh√¥ng h·ª£p l·ªá, vui l√≤ng th·ª≠ l·∫°i"
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        show_sentiment_result(result['sentiment'])

        # Hi·ªÉn th·ªã chi ti·∫øt c√°c b∆∞·ªõc trong pipeline
        show_pipeline_steps(text, corrected_text, tokenized_text, sentiment, result)
        
        return result, None

    except Exception as e:
        return None, f"Pipeline error: {e}. Please try again."

# =========================== UI ===========================
initialize_database()
global_pipeline = load_model_pipeline()

st.set_page_config(page_title="Vietnamese Sentiment Assistant", layout="wide")

st.markdown("# Nh·∫≠n di·ªán c·∫£m x√∫c ti·∫øng Vi·ªát")

col_1, col_2 = st.columns([1, 1], gap="large")

with col_1:
    st.markdown("##### Nh·∫≠p c√¢u c·∫ßn ph√¢n t√≠ch:")
    
    user_input = st.text_input(
        "Nh·∫≠p c√¢u (5-50 k√Ω t·ª±):", 
        max_chars=50, 
        key="user_input_text",
        label_visibility="collapsed"
    )

    analyze_button = st.button("Ph√¢n t√≠ch", type="primary", width="stretch")
   
    history_header_col1, history_header_col2, history_header_col3 = st.columns([4, 1, 1])

    with history_header_col1:
        st.markdown("#### L·ªãch s·ª≠")

    @st.dialog("X√°c nh·∫≠n x√≥a t·∫•t c·∫£ l·ªãch s·ª≠?")
    def confirm_delete_all():
        if st.button("Submit"):
            delete_all_records()
            st.rerun()

    with history_header_col2:
        st.button("X√≥a t·∫•t c·∫£", type="tertiary", icon="üóëÔ∏è", width="stretch", on_click=confirm_delete_all)
        
    with history_header_col3:
        refresh_button = st.button("L√†m m·ªõi", icon="üîÑ", width="stretch")

    df_history = load_data_from_sqlite()
       
    if df_history.empty:
        st.info("Ch∆∞a c√≥ l·ªãch s·ª≠!")
    else:
        df_display = df_history.copy()
        st.dataframe(df_display, 
                    hide_index=True, 
                    width="stretch",
                    selection_mode='single-row',
                    on_select='ignore',
                    column_config={
                        "id": st.column_config.NumberColumn("ID", width=25),
                        "text": st.column_config.TextColumn("VƒÉn b·∫£n", width="large"),
                        "sentiment": st.column_config.TextColumn("Nh√£n c·∫£m x√∫c", width=50),
                        "timestamp": st.column_config.TextColumn("Th·ªùi gian", width=100),
                    })

with col_2:
    if analyze_button:
            result, error = full_pipeline(user_input, global_pipeline)
                        
            if error:
                st.error(f"L·ªói: {error}")
    else:
        st.info("Vui l√≤ng nh·∫≠p m·ªôt c√¢u v√† nh·∫•n 'Ph√¢n t√≠ch' ƒë·ªÉ ƒë√°nh gi√° c·∫£m x√∫c.")